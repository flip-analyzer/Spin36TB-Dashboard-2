{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Momentum Trading System - Validation and Example Usage\n",
    "\n",
    "This notebook demonstrates how to use the momentum trading system and validates its implementation following López de Prado's methodology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import our modules\n",
    "from data.data_handler import FinancialDataHandler\n",
    "from features.fractional_diff import FractionalDifferentiator\n",
    "from features.momentum_features import MomentumFeatureEngineer\n",
    "from labeling.triple_barrier import TripleBarrierLabeler\n",
    "from validation.purged_cv import PurgedKFold, TimeSeriesValidator\n",
    "from models.ml_models import MomentumMLModel\n",
    "from backtesting.backtester import MomentumBacktester"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data handler\n",
    "symbols = ['SPY', 'QQQ', 'IWM']\n",
    "data_handler = FinancialDataHandler(symbols)\n",
    "\n",
    "# Fetch data\n",
    "start_date = '2020-01-01'\n",
    "end_date = '2023-12-31'\n",
    "data = data_handler.fetch_data(start_date, end_date)\n",
    "\n",
    "# Focus on SPY for demonstration\n",
    "spy_data = data['SPY']\n",
    "print(f\"Data shape: {spy_data.shape}\")\n",
    "print(f\"Date range: {spy_data.index[0]} to {spy_data.index[-1]}\")\n",
    "\n",
    "# Validate data quality\n",
    "quality_metrics = data_handler.validate_data_quality('SPY')\n",
    "print(\"\\nData Quality Metrics:\")\n",
    "for metric, value in quality_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fractional Differentiation Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test fractional differentiation\n",
    "frac_diff = FractionalDifferentiator()\n",
    "prices = spy_data['Close']\n",
    "\n",
    "# Find optimal d parameter\n",
    "optimal_d = frac_diff.find_optimal_d(prices, d_range=(0.0, 1.0), step=0.1)\n",
    "print(f\"Optimal fractional differentiation parameter: {optimal_d:.2f}\")\n",
    "\n",
    "# Apply fractional differentiation\n",
    "frac_diff_series = frac_diff.frac_diff_ffd(prices, optimal_d)\n",
    "\n",
    "# Validate stationarity\n",
    "original_stationarity = frac_diff.validate_stationarity(prices)\n",
    "frac_diff_stationarity = frac_diff.validate_stationarity(frac_diff_series)\n",
    "\n",
    "print(\"\\nStationarity Test Results:\")\n",
    "print(f\"Original series ADF p-value: {original_stationarity['adf']['p_value']:.4f}\")\n",
    "print(f\"Frac diff series ADF p-value: {frac_diff_stationarity['adf']['p_value']:.4f}\")\n",
    "\n",
    "# Memory preservation\n",
    "memory_correlation = frac_diff.memory_preservation_test(prices, frac_diff_series)\n",
    "print(f\"Memory preservation correlation: {memory_correlation:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create momentum features\n",
    "feature_engineer = MomentumFeatureEngineer()\n",
    "features = feature_engineer.create_momentum_features(\n",
    "    prices=spy_data['Close'],\n",
    "    volume=spy_data['Volume']\n",
    ")\n",
    "\n",
    "print(f\"Feature matrix shape: {features.shape}\")\n",
    "print(f\"Features created: {list(features.columns)}\")\n",
    "\n",
    "# Check for missing values\n",
    "missing_pct = features.isnull().sum() / len(features) * 100\n",
    "print(f\"\\nFeatures with >10% missing values:\")\n",
    "high_missing = missing_pct[missing_pct > 10]\n",
    "print(high_missing if len(high_missing) > 0 else \"None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Triple Barrier Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labels using triple barrier method\n",
    "labeler = TripleBarrierLabeler()\n",
    "\n",
    "# Calculate volatility for barriers\n",
    "returns = data_handler.get_returns('SPY')\n",
    "volatility = data_handler.get_volatility('SPY', window=20)\n",
    "\n",
    "# Create event timestamps (daily)\n",
    "t_events = spy_data.index[20:]  # Skip initial period for volatility calculation\n",
    "\n",
    "# Get triple barrier events\n",
    "events = labeler.get_events(\n",
    "    close=spy_data['Close'],\n",
    "    t_events=t_events,\n",
    "    pt_sl=[1.0, 1.0],  # Symmetric barriers\n",
    "    target=volatility,\n",
    "    min_ret=0.005  # 0.5% minimum return\n",
    ")\n",
    "\n",
    "# Get labels\n",
    "labeled_events = labeler.get_bins(events, spy_data['Close'])\n",
    "\n",
    "# Analyze label distribution\n",
    "label_analysis = labeler.analyze_label_distribution(labeled_events)\n",
    "print(\"Label Distribution Analysis:\")\n",
    "for key, value in label_analysis.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training with Purged Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align features and labels\n",
    "common_index = features.index.intersection(labeled_events.index)\n",
    "X = features.loc[common_index].fillna(method='ffill').fillna(0)\n",
    "y = labeled_events.loc[common_index]['bin']\n",
    "\n",
    "print(f\"Aligned dataset shape: X={X.shape}, y={y.shape}\")\n",
    "\n",
    "# Create sample weights\n",
    "sample_weights = labeler.get_sample_weights(\n",
    "    labeled_events.loc[common_index],\n",
    "    spy_data['Close'],\n",
    "    method='time_decay'\n",
    ")\n",
    "\n",
    "# Initialize model\n",
    "model = MomentumMLModel(\n",
    "    model_type='random_forest',\n",
    "    use_feature_selection=True,\n",
    "    n_features_select=15\n",
    ")\n",
    "\n",
    "# Purged cross-validation\n",
    "validator = TimeSeriesValidator()\n",
    "cv_results = validator.validate_model(\n",
    "    model=model,\n",
    "    X=X,\n",
    "    y=y,\n",
    "    cv_method='purged_kfold',\n",
    "    n_splits=5,\n",
    "    sample_weights=sample_weights,\n",
    "    scoring=['accuracy', 'precision', 'recall', 'f1']\n",
    ")\n",
    "\n",
    "print(\"\\nCross-Validation Results:\")\n",
    "for metric in ['accuracy', 'precision', 'recall', 'f1']:\n",
    "    mean_score = cv_results[metric].mean()\n",
    "    std_score = cv_results[metric].std()\n",
    "    print(f\"{metric}: {mean_score:.4f} (+/- {std_score*2:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Training and Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model\n",
    "model.fit(X, y, sample_weights=sample_weights)\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = model.get_feature_importance()\n",
    "print(\"Top 10 Most Important Features:\")\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "feature_importance.head(15).plot(kind='bar')\n",
    "plt.title('Top 15 Feature Importance')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate trading signals\n",
    "signals = pd.Series(model.predict(X), index=X.index)\n",
    "probabilities = pd.DataFrame(\n",
    "    model.predict_proba(X), \n",
    "    index=X.index,\n",
    "    columns=[-1, 0, 1]\n",
    ").max(axis=1)  # Use max probability as confidence\n",
    "\n",
    "# Initialize backtester\n",
    "backtester = MomentumBacktester(\n",
    "    initial_capital=100000,\n",
    "    transaction_cost=0.001,  # 0.1%\n",
    "    market_impact=0.0005,   # 0.05%\n",
    "    max_position_size=0.2   # 20% max position\n",
    ")\n",
    "\n",
    "# Run backtest\n",
    "backtest_results = backtester.backtest(\n",
    "    signals=signals,\n",
    "    prices=spy_data.loc[signals.index],\n",
    "    probabilities=probabilities,\n",
    "    position_sizing_method='kelly'\n",
    ")\n",
    "\n",
    "print(\"Backtest Results:\")\n",
    "for key, value in backtest_results.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{key}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Performance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot backtest results\n",
    "backtester.plot_results(spy_data.loc[signals.index])\n",
    "\n",
    "# Calculate monthly returns\n",
    "portfolio_df = backtester.get_portfolio_history()\n",
    "portfolio_returns = portfolio_df['portfolio_value'].pct_change().dropna()\n",
    "\n",
    "# Performance comparison\n",
    "spy_returns = spy_data.loc[portfolio_returns.index]['Close'].pct_change().dropna()\n",
    "common_index = portfolio_returns.index.intersection(spy_returns.index)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Cumulative returns comparison\n",
    "plt.subplot(2, 2, 1)\n",
    "strategy_cumret = (1 + portfolio_returns.loc[common_index]).cumprod()\n",
    "benchmark_cumret = (1 + spy_returns.loc[common_index]).cumprod()\n",
    "\n",
    "plt.plot(strategy_cumret.index, strategy_cumret, label='Strategy', linewidth=2)\n",
    "plt.plot(benchmark_cumret.index, benchmark_cumret, label='Buy & Hold', linewidth=2)\n",
    "plt.title('Cumulative Returns Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Monthly returns distribution\n",
    "plt.subplot(2, 2, 2)\n",
    "monthly_strategy = portfolio_returns.resample('M').apply(lambda x: (1+x).prod() - 1)\n",
    "monthly_benchmark = spy_returns.resample('M').apply(lambda x: (1+x).prod() - 1)\n",
    "\n",
    "plt.hist(monthly_strategy, bins=20, alpha=0.7, label='Strategy', density=True)\n",
    "plt.hist(monthly_benchmark, bins=20, alpha=0.7, label='Buy & Hold', density=True)\n",
    "plt.title('Monthly Returns Distribution')\n",
    "plt.legend()\n",
    "plt.xlabel('Monthly Return')\n",
    "\n",
    "# Rolling Sharpe ratio\n",
    "plt.subplot(2, 2, 3)\n",
    "rolling_sharpe_strategy = portfolio_returns.rolling(63).mean() / portfolio_returns.rolling(63).std() * np.sqrt(252)\n",
    "rolling_sharpe_benchmark = spy_returns.rolling(63).mean() / spy_returns.rolling(63).std() * np.sqrt(252)\n",
    "\n",
    "plt.plot(rolling_sharpe_strategy.index, rolling_sharpe_strategy, label='Strategy')\n",
    "plt.plot(rolling_sharpe_benchmark.index, rolling_sharpe_benchmark, label='Buy & Hold')\n",
    "plt.title('Rolling 3-Month Sharpe Ratio')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Signal distribution\n",
    "plt.subplot(2, 2, 4)\n",
    "signals.value_counts().sort_index().plot(kind='bar')\n",
    "plt.title('Signal Distribution')\n",
    "plt.xlabel('Signal')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Risk Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk metrics summary\n",
    "strategy_metrics = {\n",
    "    'Annualized Return': backtest_results['annualized_return'],\n",
    "    'Volatility': backtest_results['volatility'],\n",
    "    'Sharpe Ratio': backtest_results['sharpe_ratio'],\n",
    "    'Sortino Ratio': backtest_results['sortino_ratio'],\n",
    "    'Calmar Ratio': backtest_results['calmar_ratio'],\n",
    "    'Max Drawdown': backtest_results['max_drawdown'],\n",
    "    'Win Rate': backtest_results['win_rate'],\n",
    "    'Profit Factor': backtest_results['profit_factor']\n",
    "}\n",
    "\n",
    "# Benchmark metrics\n",
    "benchmark_return = spy_returns.mean() * 252\n",
    "benchmark_vol = spy_returns.std() * np.sqrt(252)\n",
    "benchmark_sharpe = benchmark_return / benchmark_vol\n",
    "\n",
    "benchmark_cumret = (1 + spy_returns).cumprod()\n",
    "benchmark_dd = (benchmark_cumret / benchmark_cumret.expanding().max() - 1).min()\n",
    "\n",
    "benchmark_metrics = {\n",
    "    'Annualized Return': benchmark_return,\n",
    "    'Volatility': benchmark_vol,\n",
    "    'Sharpe Ratio': benchmark_sharpe,\n",
    "    'Max Drawdown': benchmark_dd\n",
    "}\n",
    "\n",
    "# Create comparison table\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Strategy': [strategy_metrics.get(k, 'N/A') for k in ['Annualized Return', 'Volatility', 'Sharpe Ratio', 'Max Drawdown']],\n",
    "    'Buy & Hold': [benchmark_metrics.get(k, 'N/A') for k in ['Annualized Return', 'Volatility', 'Sharpe Ratio', 'Max Drawdown']]\n",
    "}, index=['Annualized Return', 'Volatility', 'Sharpe Ratio', 'Max Drawdown'])\n",
    "\n",
    "print(\"Performance Comparison:\")\n",
    "print(comparison_df.round(4))\n",
    "\n",
    "print(f\"\\nAdditional Strategy Metrics:\")\n",
    "print(f\"Win Rate: {strategy_metrics['Win Rate']:.2%}\")\n",
    "print(f\"Profit Factor: {strategy_metrics['Profit Factor']:.2f}\")\n",
    "print(f\"Number of Trades: {backtest_results['num_trades']}\")\n",
    "print(f\"Transaction Costs: ${backtest_results['total_costs']:.2f} ({backtest_results['cost_drag']:.2%} drag)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model Validation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"MOMENTUM TRADING SYSTEM VALIDATION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n1. DATA QUALITY:\")\n",
    "print(f\"   - Dataset: {spy_data.shape[0]} observations\")\n",
    "print(f\"   - Missing values: {quality_metrics['missing_values_pct']:.2f}%\")\n",
    "print(f\"   - Data completeness: {quality_metrics['data_completeness']:.2f}\")\n",
    "\n",
    "print(f\"\\n2. FRACTIONAL DIFFERENTIATION:\")\n",
    "print(f\"   - Optimal d parameter: {optimal_d:.2f}\")\n",
    "print(f\"   - Stationarity achieved: {frac_diff_stationarity['adf']['is_stationary']}\")\n",
    "print(f\"   - Memory preservation: {memory_correlation:.3f}\")\n",
    "\n",
    "print(f\"\\n3. FEATURE ENGINEERING:\")\n",
    "print(f\"   - Total features created: {features.shape[1]}\")\n",
    "print(f\"   - Features selected: {len(model.selected_features)}\")\n",
    "print(f\"   - Top feature: {feature_importance.index[0]}\")\n",
    "\n",
    "print(f\"\\n4. LABELING:\")\n",
    "print(f\"   - Events generated: {len(labeled_events)}\")\n",
    "print(f\"   - Label distribution: {label_analysis['label_percentages']}\")\n",
    "print(f\"   - Imbalance ratio: {label_analysis['imbalance_ratio']:.2f}\")\n",
    "\n",
    "print(f\"\\n5. MODEL VALIDATION:\")\n",
    "print(f\"   - CV Accuracy: {cv_results['accuracy'].mean():.3f} ± {cv_results['accuracy'].std():.3f}\")\n",
    "print(f\"   - CV F1-Score: {cv_results['f1'].mean():.3f} ± {cv_results['f1'].std():.3f}\")\n",
    "print(f\"   - Model type: {model.model_type}\")\n",
    "\n",
    "print(f\"\\n6. BACKTEST PERFORMANCE:\")\n",
    "print(f\"   - Total Return: {backtest_results['total_return']:.2%}\")\n",
    "print(f\"   - Sharpe Ratio: {backtest_results['sharpe_ratio']:.2f}\")\n",
    "print(f\"   - Max Drawdown: {backtest_results['max_drawdown']:.2%}\")\n",
    "print(f\"   - Win Rate: {backtest_results['win_rate']:.2%}\")\n",
    "print(f\"   - vs Buy & Hold Return: {benchmark_return:.2%}\")\n",
    "\n",
    "print(f\"\\n7. SYSTEM VALIDATION:\")\n",
    "validation_passed = (\n",
    "    frac_diff_stationarity['adf']['is_stationary'] and\n",
    "    cv_results['accuracy'].mean() > 0.33 and  # Better than random for 3-class\n",
    "    backtest_results['sharpe_ratio'] > 0 and\n",
    "    len(labeled_events) > 100\n",
    ")\n",
    "print(f\"   - Validation Status: {'PASSED' if validation_passed else 'NEEDS REVIEW'}\")\n",
    "print(f\"   - Ready for live trading: {'YES' if validation_passed and backtest_results['sharpe_ratio'] > 1.0 else 'NEEDS OPTIMIZATION'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}